{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style = \"text-align: center;\"><b>TWITTER SENTIMENT ANALYSIS</b></p>\n",
    "<div style = \"text-align: center;\">\n",
    "    <img style = \"text-align: center;\" src = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcStMoNq6Jgs5_ysqMDEATmLm8HHcH7tJqo_zR3U4h7ZbQ&s\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Context*\n",
    " - The objective of this task is to detect sentiment from video game reviews left on Amazon.\n",
    " - Based on project found here:  https://github.com/koosha-t/Sentiment-Analysis-NLP-for-Marketting?tab=readme-ov-file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='dark', color_codes=True, font_scale=1.5)\n",
    "\n",
    "#NLP\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.snowball import SnowballStemmer #You can call SnowballStemmer, but I believe everything we are working with is in English\n",
    "from nltk.stem import WordNetLemmatizer #Lemmatizes words\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Annoying warnings begone!\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style = \"text-align:center;\"><b> 1. Downloading and creating the Amazon review dataset</b></p>\n",
    "\n",
    " - ### **NOTE:** This data is not in pure JSON and will need to be converted using ndjson\n",
    " - ### Creating two sample datasets: \n",
    "     - One with a balanced amount of reviews that's representative of reviews\n",
    "     - One that is 100k completely random reviews\n",
    "\n",
    "\n",
    "### **NOTE**: *Done in a separate notebook*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style = \"text-align:center;\"><b> 2. Label each review with a sentiment score <i>(-1 to 1)</i> </b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ### Loading up our sampled_data.csv \n",
    " - ### Performing some NLP preprocessing with NLTK\n",
    "    - *Going to need to use NLTK doco a lot here*\n",
    " - ### Labeling each review with a sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4500 entries, 0 to 4499\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   asin        4500 non-null   object \n",
      " 1   overall     4500 non-null   float64\n",
      " 2   reviewText  4500 non-null   object \n",
      " 3   summary     4500 non-null   object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 140.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Loading our sampled dataset\n",
    "sampled_csv= pd.read_csv('/home/bglid/bglidden/learning_files/handsonML3/NLTK_Sentiment_Analysis/Datasets/sampled_data.csv')\n",
    "sampled_reviews = pd.DataFrame(sampled_csv)\n",
    "sampled_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Preprocessing\n",
    "*We are not removing stopwords in this instance*\n",
    "\n",
    " - Tokenize\n",
    "    - POS tagging\n",
    " - Stemming\n",
    " - Lemm\n",
    " - Label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bglid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/bglid/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "test_review = sampled_reviews['reviewText'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Tokenizing**\n",
    "\n",
    " - We want to use word_tokenize, because when we pass this to a stemmer, we want it to check each word.\n",
    "     - *compared to sent_tokenize, which will pass each sentence to the stemmer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not need this function anymore\n",
    "\n",
    "# #Tokenizer function\n",
    "# def tokenizing_text(sentence):\n",
    "#     tokenized_sent = sent_tokenize(sentence) \n",
    "#     # tokenized_words = [word_tokenize(word) for word in tokenized_sent] #wow I am stupid this is what I needed to remove\n",
    "#     return tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The graphics seem dated and rushed.', 'The gameplay was laborious and after 30 minutes I simply could not play anymore as it seemed I was wasting my time.', 'I was playing with two player option, but the second player wound up always having to be a robot.', \"The second stage was having each character escape from the hospital and fight off robots and solve puzzles to open doors; I don't rememeber any of that in the movie.\", 'I would not recommend.']\n"
     ]
    }
   ],
   "source": [
    "example = sent_tokenize(test_review)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We need to add POS tagging here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagged_example = pos_tag(example)\n",
    "# print(tagged_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Stemming**\n",
    "\n",
    " - *Stemming using the Snowball Stemmer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the graphics seem dated and rushed.',\n",
       " 'the gameplay was laborious and after 30 minutes i simply could not play anymore as it seemed i was wasting my time.',\n",
       " 'i was playing with two player option, but the second player wound up always having to be a robot.',\n",
       " \"the second stage was having each character escape from the hospital and fight off robots and solve puzzles to open doors; i don't rememeber any of that in the movie.\",\n",
       " 'i would not recommend.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing using our stemmer on our example sentence\n",
    "stemmer = SnowballStemmer(language='english') #This performs better\n",
    "# stemmer = PorterStemmer()\n",
    "example_stemmed = [stemmer.stem(word) for word in example]\n",
    "example_stemmed #Nice!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Lemmatizing**\n",
    "\n",
    "    - Going to test this out using *WordNetLemmatizer*\n",
    "\n",
    "    - Should we stemm and lemmatize/?? We might need to do some pos tagging\n",
    "\n",
    "### WE ARE GOING TO SKIP THIS FOR NOW TO SKIP POS TAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need wordnet\n",
    "# nltk.download('wordnet')\n",
    "#Building our Lemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "example_lemmas = [wnl.lemmatize(word) for word in example_stemmed]\n",
    "# example_lemmas #uh oh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Building our preprocessor into a Scikit-Learn Transformer*\n",
    "\n",
    " - We will use this to actually process the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting off creating a sklearn custom Transformer class to fit_transform our text\n",
    "#Does not include sentiment analysis\n",
    "class NLTKPreprocessing(BaseEstimator, TransformerMixin):\n",
    "    #function to fit our data\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    #Transforming function that returns our preprocessed text\n",
    "    def transform(self, X, y=None):\n",
    "        #Tokenizing each row in a Dataframe\n",
    "        tokenized_text = []\n",
    "        for doc in X:\n",
    "            tokenized_text.append(sent_tokenize(doc))\n",
    "            \n",
    "        #Stemming the now tokenized lists of text\n",
    "        stemmer = SnowballStemmer(language='english') \n",
    "        stemmed_tokens = []\n",
    "        for review in tokenized_text:\n",
    "            sentence = [] #List variable to hold each review\n",
    "            for token in review:\n",
    "                #Stemming each word in the review\n",
    "                sentence.append(stemmer.stem(token))\n",
    "            #Appending each stemmed review \n",
    "            stemmed_tokens.append(sentence)\n",
    "            \n",
    "        return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>stemmed tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0007RDM5Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The graphics seem dated and rushed.  The gamep...</td>\n",
       "      <td>-</td>\n",
       "      <td>[the graphics seem dated and rushed., the game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B007P6Y684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>One Star</td>\n",
       "      <td>[cheap]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00BQZ5EWW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>background history\\nI remember seeing ROME tot...</td>\n",
       "      <td>ROME II: BETA cause thats the quality they rel...</td>\n",
       "      <td>[background history\\ni remember seeing rome to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0016BVY7U</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Do not buy this game! The installation code in...</td>\n",
       "      <td>Game won't install because the included code d...</td>\n",
       "      <td>[do not buy this game!, the installation code ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0178FWY62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Its loud AF. Like one of the fans is hitting s...</td>\n",
       "      <td>Does not work as advertised.</td>\n",
       "      <td>[its loud af., like one of the fans is hitting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>B000VTQ3LU</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great product, it worked as described and I ha...</td>\n",
       "      <td>Great product, it worked as described and I ha...</td>\n",
       "      <td>[great product, it worked as described and i h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>B00CMQTUSS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AMAZING price. Love it.</td>\n",
       "      <td>Thumbs Up</td>\n",
       "      <td>[amazing price., love it.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>B00JK00S0S</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Game is seriously one of the best games I have...</td>\n",
       "      <td>Six star game five an half star seller.</td>\n",
       "      <td>[game is seriously one of the best games i hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>B0001KUE7S</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This review is both for the X-BOX as well as t...</td>\n",
       "      <td>Now get your lazy butt to Mars, Space Marine !</td>\n",
       "      <td>[this review is both for the x-box as well as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>B00BGAA0SU</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I'm a huge Infamous fan as I played all of the...</td>\n",
       "      <td>Great game!</td>\n",
       "      <td>[i'm a huge infamous fan as i played all of th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            asin  overall                                         reviewText  \\\n",
       "0     B0007RDM5Q      1.0  The graphics seem dated and rushed.  The gamep...   \n",
       "1     B007P6Y684      1.0                                              Cheap   \n",
       "2     B00BQZ5EWW      1.0  background history\\nI remember seeing ROME tot...   \n",
       "3     B0016BVY7U      1.0  Do not buy this game! The installation code in...   \n",
       "4     B0178FWY62      1.0  Its loud AF. Like one of the fans is hitting s...   \n",
       "...          ...      ...                                                ...   \n",
       "4495  B000VTQ3LU      5.0  Great product, it worked as described and I ha...   \n",
       "4496  B00CMQTUSS      5.0                            AMAZING price. Love it.   \n",
       "4497  B00JK00S0S      5.0  Game is seriously one of the best games I have...   \n",
       "4498  B0001KUE7S      5.0  This review is both for the X-BOX as well as t...   \n",
       "4499  B00BGAA0SU      5.0  I'm a huge Infamous fan as I played all of the...   \n",
       "\n",
       "                                                summary  \\\n",
       "0                                                     -   \n",
       "1                                              One Star   \n",
       "2     ROME II: BETA cause thats the quality they rel...   \n",
       "3     Game won't install because the included code d...   \n",
       "4                          Does not work as advertised.   \n",
       "...                                                 ...   \n",
       "4495  Great product, it worked as described and I ha...   \n",
       "4496                                          Thumbs Up   \n",
       "4497            Six star game five an half star seller.   \n",
       "4498     Now get your lazy butt to Mars, Space Marine !   \n",
       "4499                                        Great game!   \n",
       "\n",
       "                                         stemmed tokens  \n",
       "0     [the graphics seem dated and rushed., the game...  \n",
       "1                                               [cheap]  \n",
       "2     [background history\\ni remember seeing rome to...  \n",
       "3     [do not buy this game!, the installation code ...  \n",
       "4     [its loud af., like one of the fans is hitting...  \n",
       "...                                                 ...  \n",
       "4495  [great product, it worked as described and i h...  \n",
       "4496                         [amazing price., love it.]  \n",
       "4497  [game is seriously one of the best games i hav...  \n",
       "4498  [this review is both for the x-box as well as ...  \n",
       "4499  [i'm a huge infamous fan as i played all of th...  \n",
       "\n",
       "[4500 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing our transformer\n",
    "text_preprocessor = NLTKPreprocessing()\n",
    "tokenized_stemmed_doc = text_preprocessor.fit_transform(sampled_reviews['reviewText']) #did that actually work????\n",
    "\n",
    "# sampled_reviews['stemmed tokens'] = tokenized_stemmed_doc # We don't actually need to join this column into the DF right now\n",
    "# sampled_reviews #wow #NICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Scoring using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/bglid/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building out our sentiment scoring function:\n",
    "def review_sentiment(review):\n",
    "    #Init Sentiment Analysis \n",
    "    sid = SentimentIntensityAnalyzer() \n",
    "    review_sentiment = []\n",
    "    #counter variables for getting the average score\n",
    "    count = 0.0\n",
    "    score = 0.0\n",
    "    #Getting the sentiment of each sentence in the review\n",
    "    for sentence in review:\n",
    "        sentence_polarity = sid.polarity_scores(sentence)\n",
    "        score += sentence_polarity['compound']\n",
    "        count += 1\n",
    "    #calculating the overall sentiment by way of the mean of each polarity score\n",
    "    review_score = round((score / count), 4)\n",
    "    return review_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating our Scikit-Learn Transformer for getting each review's sentiment:\n",
    "class SentimentScorer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    #Transformer function that calculates each review's sentiment\n",
    "    def transform(self, X, y = None):\n",
    "        sentiment_scores = []\n",
    "        for doc in X:\n",
    "            #Getting the sentiment score for the review\n",
    "            sentiment = review_sentiment(doc)\n",
    "            sentiment_scores.append(sentiment)\n",
    "        \n",
    "        return sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #Test\n",
    "# sample_stemmed_sent = tokenized_stemmed_doc[0:5].copy()\n",
    "# print(sample_stemmed_sent)\n",
    "# # print(f'\\n Polarity score: {review_sentiment(sample_stemmed_sent)}') #Good for now\n",
    "\n",
    "# #Testing our transformer\n",
    "# scorer = SentimentScorer()\n",
    "# scores = scorer.transform(sample_stemmed_sent)\n",
    "# scores #WOW again lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building out our Final Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Text Preprocessing&#x27;, NLTKPreprocessing()),\n",
       "                (&#x27;Sentiment Scorer&#x27;, SentimentScorer())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Text Preprocessing&#x27;, NLTKPreprocessing()),\n",
       "                (&#x27;Sentiment Scorer&#x27;, SentimentScorer())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NLTKPreprocessing</label><div class=\"sk-toggleable__content\"><pre>NLTKPreprocessing()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SentimentScorer</label><div class=\"sk-toggleable__content\"><pre>SentimentScorer()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Text Preprocessing', NLTKPreprocessing()),\n",
       "                ('Sentiment Scorer', SentimentScorer())])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building our final pipeline to take care of this entire process\n",
    "final_pipeline = Pipeline([\n",
    "    ('Text Preprocessing', NLTKPreprocessing()),\n",
    "    ('Sentiment Scorer', SentimentScorer())\n",
    "])\n",
    "final_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring each review\n",
    "review_scores = final_pipeline.fit_transform(sampled_reviews['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>sentiment score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0007RDM5Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The graphics seem dated and rushed.  The gamep...</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B007P6Y684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>One Star</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00BQZ5EWW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>background history\\nI remember seeing ROME tot...</td>\n",
       "      <td>ROME II: BETA cause thats the quality they rel...</td>\n",
       "      <td>-0.0874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0016BVY7U</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Do not buy this game! The installation code in...</td>\n",
       "      <td>Game won't install because the included code d...</td>\n",
       "      <td>-0.2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0178FWY62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Its loud AF. Like one of the fans is hitting s...</td>\n",
       "      <td>Does not work as advertised.</td>\n",
       "      <td>0.1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>B000VTQ3LU</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great product, it worked as described and I ha...</td>\n",
       "      <td>Great product, it worked as described and I ha...</td>\n",
       "      <td>0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>B00CMQTUSS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AMAZING price. Love it.</td>\n",
       "      <td>Thumbs Up</td>\n",
       "      <td>0.6114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>B00JK00S0S</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Game is seriously one of the best games I have...</td>\n",
       "      <td>Six star game five an half star seller.</td>\n",
       "      <td>0.9628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>B0001KUE7S</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This review is both for the X-BOX as well as t...</td>\n",
       "      <td>Now get your lazy butt to Mars, Space Marine !</td>\n",
       "      <td>0.0916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>B00BGAA0SU</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I'm a huge Infamous fan as I played all of the...</td>\n",
       "      <td>Great game!</td>\n",
       "      <td>0.7339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            asin  overall                                         reviewText  \\\n",
       "0     B0007RDM5Q      1.0  The graphics seem dated and rushed.  The gamep...   \n",
       "1     B007P6Y684      1.0                                              Cheap   \n",
       "2     B00BQZ5EWW      1.0  background history\\nI remember seeing ROME tot...   \n",
       "3     B0016BVY7U      1.0  Do not buy this game! The installation code in...   \n",
       "4     B0178FWY62      1.0  Its loud AF. Like one of the fans is hitting s...   \n",
       "...          ...      ...                                                ...   \n",
       "4495  B000VTQ3LU      5.0  Great product, it worked as described and I ha...   \n",
       "4496  B00CMQTUSS      5.0                            AMAZING price. Love it.   \n",
       "4497  B00JK00S0S      5.0  Game is seriously one of the best games I have...   \n",
       "4498  B0001KUE7S      5.0  This review is both for the X-BOX as well as t...   \n",
       "4499  B00BGAA0SU      5.0  I'm a huge Infamous fan as I played all of the...   \n",
       "\n",
       "                                                summary  sentiment score  \n",
       "0                                                     -          -0.1551  \n",
       "1                                              One Star           0.0000  \n",
       "2     ROME II: BETA cause thats the quality they rel...          -0.0874  \n",
       "3     Game won't install because the included code d...          -0.2051  \n",
       "4                          Does not work as advertised.           0.1389  \n",
       "...                                                 ...              ...  \n",
       "4495  Great product, it worked as described and I ha...           0.4939  \n",
       "4496                                          Thumbs Up           0.6114  \n",
       "4497            Six star game five an half star seller.           0.9628  \n",
       "4498     Now get your lazy butt to Mars, Space Marine !           0.0916  \n",
       "4499                                        Great game!           0.7339  \n",
       "\n",
       "[4500 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampled_reviews['sentiment score'] = review_scores \n",
    "sampled_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style = \"text-align:center;\"><b> 3. Evaluate the performance of our sentiment analyzer by comparing the sentiment scores with review ratings </b></p>\n",
    "\n",
    " - Display our scores and group them into Positive, Neutral, and Negative\n",
    " - Group the True ratings into positive, neugtral, and negative to compare the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style = \"text-align:center;\"><b> 4. Repeat the last two steps with deep learning models <i>BERT</i></b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style = \"text-align:center;\"><b> 5. Report and visualize the results</b></p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoML3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
